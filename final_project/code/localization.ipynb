{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tqdm, tqdm.notebook\n",
    "\n",
    "tqdm.tqdm = tqdm.notebook.tqdm  # notebook-friendly progress bars\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from hloc import (\n",
    "    extract_features,\n",
    "    match_features,\n",
    "    reconstruction,\n",
    "    visualization,\n",
    "    pairs_from_exhaustive,\n",
    ")\n",
    "from hloc.visualization import plot_images, read_image\n",
    "from hloc.utils import viz_3d\n",
    "import torch\n",
    "import pycolmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run sfm and display 3D model (disk   disk_lightglue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(3)\n",
    "print(\"torch.cuda.current_device()=\", torch.cuda.get_device_name())\n",
    "\n",
    "images = Path(\"/home/cv_stu_03/Hierarchical-Localization/project/images/MainLibrary/ReconstructionDataset\")\n",
    "sfm_dir= Path(\"/home/cv_stu_03/Hierarchical-Localization/project/Comparison/disk_disk+lightglue/sfm\")\n",
    "sfm_pairs= Path(\"/home/cv_stu_03/Hierarchical-Localization/project/Comparison/disk_disk+lightglue/pairs-sfm.txt\")\n",
    "features= Path(\"/home/cv_stu_03/Hierarchical-Localization/project/Comparison/disk_disk+lightglue/features.h5\")\n",
    "matches= Path(\"/home/cv_stu_03/Hierarchical-Localization/project/Comparison/disk_disk+lightglue/matches.h5\")\n",
    "references = [p.relative_to(images).as_posix() for p in (images ).iterdir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = pycolmap.Reconstruction(str(sfm_dir))\n",
    "\n",
    "fig = viz_3d.init_figure()\n",
    "viz_3d.plot_reconstruction(\n",
    "    fig, model, color=\"rgba(255,0,0,0.5)\", name=\"mapping\", points_rgb=True\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visiualize keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization.visualize_sfm_2d(model, images, color_by=\"visibility\", n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = Path(\"/home/cv_stu_03/Hierarchical-Localization/project/local_data/images_from_local\")\n",
    "\n",
    "image_reference =sorted([p.relative_to(image_path).as_posix() for p in (image_path).iterdir()])\n",
    "\n",
    "print(len(image_reference), \"localization images\")\n",
    "\n",
    "plot_images([read_image(image_path/r) for r in image_reference], dpi=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_conf = extract_features.confs[\"disk\"]\n",
    "matcher_conf = match_features.confs[\"disk+lightglue\"]\n",
    "loc_pairs = Path(\"/home/cv_stu_03/Hierarchical-Localization/project/pairs-from-loc.txt\")\n",
    "extract_features.main(\n",
    "    feature_conf, image_path, image_list=image_reference, feature_path=features, overwrite=True\n",
    ")\n",
    "pairs_from_exhaustive.main(loc_pairs, image_list=image_reference, ref_list=references)\n",
    "match_features.main(\n",
    "    matcher_conf, loc_pairs, features=features, matches=matches, overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycolmap\n",
    "from hloc.localize_sfm import QueryLocalizer, pose_from_cluster\n",
    "\n",
    "cameras = []\n",
    "rets = []\n",
    "logs = []\n",
    "\n",
    "for i in range(len(image_reference)):\n",
    "    # print(image_path/image_reference[i])\n",
    "\n",
    "    camera = pycolmap.infer_camera_from_image(image_path / image_reference[i])\n",
    "    ref_ids = [model.find_image_with_name(r).image_id for r in references]\n",
    "    conf = {\n",
    "        \"estimation\": {\"ransac\": {\"max_error\": 12}},\n",
    "        \"refinement\": {\"refine_focal_length\": True, \"refine_extra_params\": True},\n",
    "    }\n",
    "    localizer = QueryLocalizer(model, conf)\n",
    "    # print(str(image_path/image_reference[i]))\n",
    "    ret, log = pose_from_cluster(localizer, str(image_reference[i]), camera, ref_ids, features, matches)\n",
    "    cameras.append(camera)\n",
    "    rets.append(ret)\n",
    "    logs.append(log)\n",
    "\n",
    "# print(f'found {ret[\"num_inliers\"]}/{len(ret[\"inliers\"])} inlier correspondences.')\n",
    "# visualization.visualize_loc_from_log(images, image_reference, log, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(image_reference)):\n",
    "    print(\"matrix[\",i,\"]:   \",rets[i][\"cam_from_world\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(23,26):\n",
    "#     pose = pycolmap.Image(cam_from_world=rets[i][\"cam_from_world\"])\n",
    "#     viz_3d.plot_camera_colmap(\n",
    "#         fig, pose, cameras[i], color=\"rgba(0,255,0,0.5)\", name=image_reference[i], fill=True\n",
    "#     )\n",
    "#     # visualize 2D-3D correspodences\n",
    "#     inl_3d = np.array(\n",
    "#         [model.points3D[pid].xyz for pid in np.array(logs[i][\"points3D_ids\"])[rets[i][\"inliers\"]]]\n",
    "#     )\n",
    "#     viz_3d.plot_points(fig, inl_3d, color=\"lime\", ps=1, name=image_reference[i])\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print the camera matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rets[2][\"cam_from_world\"])\n",
    "# print(rets[3][\"cam_from_world\"])\n",
    "# print(rets[4][\"cam_from_world\"])\n",
    "\n",
    "# rm1 = rets[2][\"cam_from_world\"].rotation.matrix()\n",
    "# rm2 = rets[3][\"cam_from_world\"].rotation.matrix()\n",
    "# rm3 = rets[4][\"cam_from_world\"].rotation.matrix()\n",
    "\n",
    "# print(\"rm1: \", rm1)\n",
    "# print(\"rm2: \", rm2)\n",
    "# print(\"rm3: \", rm3)\n",
    "\n",
    "# tm1 = rets[2][\"cam_from_world\"].translation\n",
    "# tm2 = rets[3][\"cam_from_world\"].translation\n",
    "# tm3 = rets[4][\"cam_from_world\"].translation\n",
    "\n",
    "# print(\"tm1: \", tm1)\n",
    "# print(\"tm2: \", tm2)\n",
    "# print(\"tm3: \", tm3)\n",
    "\n",
    "# rotation_matrix = ret[\"cam_from_world\"].rotation.matrix()\n",
    "# print(\"rotaion: \" ,rotation_matrix)\n",
    "\n",
    "# translation_matrix = ret[\"cam_from_world\"].translation\n",
    "# print(\"translation: \",translation_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check frame consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "def check_pose_consistency(prev_rotation, curr_rotation, prev_translation, curr_translation, threshold_angle=10, threshold_translation=0.5):\n",
    "    \"\"\"\n",
    "    Check if the relative pose difference between two frames is within a reasonable range,\n",
    "    considering both rotation and translation. The inputs are the rotation and translation matrices\n",
    "    for both frames.\n",
    "    \n",
    "    Args:\n",
    "        prev_rotation: Previous frame rotation matrix (3x3).\n",
    "        curr_rotation: Current frame rotation matrix (3x3).\n",
    "        prev_translation: Previous frame translation vector (3x1).\n",
    "        curr_translation: Current frame translation vector (3x1).\n",
    "        threshold_angle: Maximum allowed rotation angle difference (in degrees).\n",
    "        threshold_translation: Maximum allowed translation difference (in meters).\n",
    "\n",
    "    Returns:\n",
    "        True if the poses are consistent, False otherwise.\n",
    "    \"\"\"\n",
    "    # Compute the relative rotation matrix (from prev to curr)\n",
    "    relative_rotation = curr_rotation.T @ prev_rotation  # curr to prev, so we use the transpose of prev_rotation\n",
    "    # Convert relative rotation matrix to rotation vector and compute the angle\n",
    "    rotation_vector = R.from_matrix(relative_rotation).as_rotvec()\n",
    "    rotation_angle = np.linalg.norm(rotation_vector) * (180 / np.pi)  # Convert to degrees\n",
    "    \n",
    "    # Compute the relative translation vector (from prev to curr)\n",
    "    relative_translation = curr_translation - prev_translation\n",
    "    translation_distance = np.linalg.norm(relative_translation)  # Euclidean distance between the translation vectors\n",
    "    \n",
    "    # Check if the rotation angle and translation distance are within the thresholds\n",
    "    is_rotation_consistent = rotation_angle < threshold_angle\n",
    "    is_translation_consistent = translation_distance < threshold_translation\n",
    "    \n",
    "    # Both rotation and translation must be consistent\n",
    "    return is_rotation_consistent and is_translation_consistent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm1 = rets[23][\"cam_from_world\"].rotation.matrix()\n",
    "rm2 = rets[24][\"cam_from_world\"].rotation.matrix()\n",
    "rm3 = rets[25][\"cam_from_world\"].rotation.matrix()\n",
    "\n",
    "tm1 = rets[23][\"cam_from_world\"].translation\n",
    "tm2 = rets[24][\"cam_from_world\"].translation\n",
    "tm3 = rets[25][\"cam_from_world\"].translation\n",
    "\n",
    "if check_pose_consistency(rm1, rm2, tm1, tm2):\n",
    "    print(\"pose between 23 and 24 is consistent\")\n",
    "else:\n",
    "    print(\"pose between 23 and 24 is not consistent\")\n",
    "\n",
    "if check_pose_consistency(rm1, rm3, tm1, tm3):\n",
    "    print(\"pose between 23 and 25 is consistent\")\n",
    "else:\n",
    "    print(\"pose between 23 and 25 is not consistent\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first initialize the camera pose roughly   \n",
    "## and fix the wrong poses in the first 10 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_pose =np.copy(rets[0][\"cam_from_world\"])\n",
    "temp_camera_pose = np.copy(rets[0][\"cam_from_world\"])\n",
    "temp_rm = np.copy(rets[0][\"cam_from_world\"].rotation.matrix())\n",
    "temp_tm = np.copy(rets[0][\"cam_from_world\"].translation)\n",
    "\n",
    "\n",
    "for i in range(1,10):\n",
    "    temp_rm+=rets[i][\"cam_from_world\"].rotation.matrix()\n",
    "    temp_tm+=rets[i][\"cam_from_world\"].translation\n",
    "temp_rm = temp_rm/10\n",
    "temp_tm = temp_tm/10\n",
    "\n",
    "\n",
    "correct_camera_pose =[]\n",
    "wrong_camera_pose = []\n",
    "for i in range(10):\n",
    "    if check_pose_consistency(temp_rm, rets[i][\"cam_from_world\"].rotation.matrix(), temp_tm, rets[i][\"cam_from_world\"].translation,threshold_angle=30, threshold_translation=10):\n",
    "        print(\"pose[\",i,\"] is consistent\")\n",
    "        correct_camera_pose.append(rets[i][\"cam_from_world\"])\n",
    "    else:\n",
    "        print(\"pose[\",i,\"] is not consistent\")\n",
    "        wrong_camera_pose.append(rets[i][\"cam_from_world\"])\n",
    "\n",
    "\n",
    "\n",
    "camera_pose = np.copy(correct_camera_pose[0])\n",
    "temp_camera_pose = np.copy(correct_camera_pose[(len(correct_camera_pose)-1)])\n",
    "temp_rm = np.copy(correct_camera_pose[0].rotation.matrix())\n",
    "temp_tm = np.copy(correct_camera_pose[0].translation)\n",
    "for i in range(len(correct_camera_pose)):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    else:\n",
    "        temp_rm+=correct_camera_pose[i].rotation.matrix()\n",
    "        temp_tm+=correct_camera_pose[i].translation\n",
    "temp_rm = temp_rm/len(correct_camera_pose)\n",
    "temp_tm = temp_tm/len(correct_camera_pose)\n",
    "\n",
    "camera_pose = pycolmap.Rigid3d(temp_rm, temp_tm)\n",
    "\n",
    "\n",
    "print(camera_pose)\n",
    "for i in range(len(wrong_camera_pose)):\n",
    "    rets[i][\"cam_from_world\"] = camera_pose\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print out other images to check if they are reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10,len(image_reference)):\n",
    "    if check_pose_consistency(camera_pose.rotation.matrix(), rets[i][\"cam_from_world\"].rotation.matrix(), camera_pose.translation, rets[i][\"cam_from_world\"].translation,threshold_angle=30, threshold_translation=10):\n",
    "        print(\"pose[\",i,\"] is consistent\")\n",
    "    else:\n",
    "        print(\"pose[\",i,\"] is not consistent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fix wrong frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix(i,flag):\n",
    "    if(flag==0):\n",
    "        rm1 = rets[i-1][\"cam_from_world\"].rotation.matrix()\n",
    "        rm2 = rets[i+1][\"cam_from_world\"].rotation.matrix()\n",
    "\n",
    "        tm1 = rets[i-1][\"cam_from_world\"].translation\n",
    "        tm2 = rets[i+1][\"cam_from_world\"].translation\n",
    "\n",
    "        rm_avg = (rm1 + rm2) / 2\n",
    "        tm_avg = (tm1 + tm2) / 2\n",
    "\n",
    "        rets[i][\"cam_from_world\"] = pycolmap.Rigid3d(rm_avg, tm_avg)\n",
    "    else:\n",
    "        rm1 = rets[i-2][\"cam_from_world\"].rotation.matrix()\n",
    "        rm2 = rets[i-1][\"cam_from_world\"].rotation.matrix()\n",
    "\n",
    "        tm1 = rets[i-2][\"cam_from_world\"].translation\n",
    "        tm2 = rets[i-1][\"cam_from_world\"].translation\n",
    "\n",
    "        rm_avg = rm2 * 2 - rm1\n",
    "        tm_avg = tm2 * 2 - tm1\n",
    "\n",
    "        rets[i][\"cam_from_world\"] = pycolmap.Rigid3d(rm_avg, tm_avg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fix the wrong images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10,len(image_reference)-1):\n",
    "    if check_pose_consistency(camera_pose.rotation.matrix(), rets[i][\"cam_from_world\"].rotation.matrix(), camera_pose.translation, rets[i][\"cam_from_world\"].translation,threshold_angle=30, threshold_translation=10):\n",
    "        # renew the camera pose = [ old camera pose * (i-1) + new camera pose ] / i\n",
    "        print(\"pose[\",i,\"] is consistent\")\n",
    "        \n",
    "\n",
    "    else:\n",
    "        if check_pose_consistency(camera_pose.rotation.matrix(), rets[i+1][\"cam_from_world\"].rotation.matrix(), camera_pose.translation, rets[i+1][\"cam_from_world\"].translation,threshold_angle=30, threshold_translation=10):\n",
    "            print(\"pose[\",i,\"] is not consistent but pose[\",i+1,\"] is consistent\")\n",
    "            fix(i,0)\n",
    "        else:\n",
    "            print(\"pose[\",i,\"] is not consistent and pose[\",i+1,\"] is not consistent\")\n",
    "            fix(i,1)\n",
    "\n",
    "\n",
    "    camera_pose = pycolmap.Rigid3d(rets[i][\"cam_from_world\"].rotation.matrix()/i+(i-1)*camera_pose.rotation.matrix()/i, rets[i][\"cam_from_world\"].translation/i+(i-1)*camera_pose.translation/i)\n",
    "\n",
    "if check_pose_consistency(camera_pose.rotation.matrix(), rets[len(image_reference)-1][\"cam_from_world\"].rotation.matrix(), camera_pose.translation, rets[len(image_reference)-1][\"cam_from_world\"].translation,threshold_angle=30, threshold_translation=10):\n",
    "    print(\"pose[\",len(image_reference)-1,\"] is consistent\")\n",
    "else:\n",
    "    print(\"pose[\",len(image_reference)-1,\"] is not consistent\")\n",
    "    rets[len(image_reference)-1][\"cam_from_world\"] = camera_pose\n",
    "\n",
    "    \n",
    "print(camera_pose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(image_reference)):\n",
    "    print(\"matrix[\",i,\"]:   \",rets[i][\"cam_from_world\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30,35):\n",
    "    pose = pycolmap.Image(cam_from_world=rets[i][\"cam_from_world\"])\n",
    "    viz_3d.plot_camera_colmap(\n",
    "        fig, pose, cameras[i], color=\"rgba(0,255,0,0.5)\", name=image_reference[i], fill=True\n",
    "    )\n",
    "    # visualize 2D-3D correspodences\n",
    "    inl_3d = np.array(\n",
    "        [model.points3D[pid].xyz for pid in np.array(logs[i][\"points3D_ids\"])[rets[i][\"inliers\"]]]\n",
    "    )\n",
    "    viz_3d.plot_points(fig, inl_3d, color=\"lime\", ps=1, name=image_reference[i])\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
